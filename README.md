# XR-DS-seq-Tutorial

GitHub repository tutorial for XR-Seq and Damage-Seq methodologies, providing code examples, datasets, and documentation for studying DNA damage and repair processes.

## Introduction to NGS (UNDER CONSTRUCTION)

This section provides an overview of Next-Generation Sequencing (NGS) technologies, their applications, and their significance in DNA damage and repair studies.

## Introduction to XR-seq (UNDER CONSTRUCTION)

## Introduction to Damage-seq (UNDER CONSTRUCTION)

## NGS File Format

This section explains the file formats that you will encounter troughout the tutorial. You can find more detail about each of these formats together with others from the [link](https://genome.ucsc.edu/FAQ/FAQformat.html).

- FASTQ:

  - The FASTQ format is used to store both the sequencing reads and their corresponding quality scores.
  - It consists of four lines per sequence read:
  - Line 1: Begins with a '@' symbol followed by a unique identifier for the read.
  - Line 2: Contains the actual nucleotide sequence of the read.
  - Line 3: Starts with a '+' symbol and may optionally contain the same unique identifier as Line 1.
  - Line 4: Contains the quality scores corresponding to the nucleotides in Line 2.
  - FASTQ files are commonly generated by sequencing platforms and are widely used as input for various NGS data analysis tools.

- FASTA:

  - The FASTA format is a simple and widely used text-based format for representing nucleotide or protein sequences.
  - Each sequence in a FASTA file consists of two parts:
    - A single-line description or identifier that starts with a '>' symbol, followed by a sequence identifier or description.
    - The sequence data itself, which can span one or more lines.
  - The sequence lines contain the actual nucleotide or amino acid symbols representing the sequence.
  - FASTA files can store multiple sequences, each with its own identifier and sequence data.
  - FASTA format is commonly used for storing and exchanging sequences, such as reference genomes, gene sequences, or protein sequences.
  - Many bioinformatics tools and databases accept FASTA files as input for various sequence analysis tasks, including alignment, motif discovery, and similarity searches.

- SAM/BAM:

  - SAM (Sequence Alignment/Map) is a text-based format used to store the alignment information of reads to a reference genome.
  - BAM (Binary Alignment/Map) is the binary equivalent of SAM, which is more compact and allows for faster data processing.
  - Both SAM and BAM files contain the same information, including read sequences, alignment positions, mapping qualities, and optional tags for additional metadata.
  - SAM/BAM files are crucial for downstream analysis tasks such as variant calling, differential expression analysis, and visualization in genome browsers.
  - SAM/BAM files can be generated using aligners like Bowtie2 or BWA.

- BED:

  - BED (Browser Extensible Data) is a widely used format for representing genomic intervals or features.
  - It consists of a tab-separated plain-text file with columns representing different attributes of each genomic feature.
  - The standard BED format includes columns for chromosome, start position, end position, feature name, and additional optional columns for annotations or scores.
  - BED files are commonly used for visualizing and analyzing genomic features such as gene coordinates, binding sites, peaks, or regulatory regions.
  - BED files can be generated from BAM files using tools like BEDTools or samtools.

- BEDGRAPH:

  - BEDGRAPH is a file format used to represent continuous numerical data across the genome, such as signal intensities, coverage, or scores.
  - Similar to BED files, BEDGRAPH files are plain-text files with columns representing genomic intervals and corresponding values.
  - The standard BEDGRAPH format includes columns for chromosome, start position, end position, and a numerical value representing the data for that interval.
  - BEDGRAPH files are typically used to visualize and analyze genome-wide data, such as ChIP-seq signal, DNA methylation levels, or RNA-seq coverage.
  - The values in a BEDGRAPH file can be positive or negative, representing different aspects of the data.
  - BEDGRAPH files can be generated from BAM files using tools like BEDTools or bedGraphToBigWig.

- BigWig:

  - BigWig is a binary file format designed for efficient storage and retrieval of large-scale numerical data across the genome.
  - BigWig files are created from BEDGRAPH files and provide a compressed and indexed representation of the data, allowing for fast random access and visualization.
  - BigWig files store the data in a binary format and include additional indexing information for quick retrieval of data within specific genomic regions.
  - They are commonly used for visualizing and analyzing genome-wide data in genome browsers or for performing quantitative analyses across different genomic regions.
  - BigWig files can be generated from BEDGRAPH files using tools like bedGraphToBigWig or through conversion from other formats like BAM or WIG.

## Create conda environment

Initially, you will create and activate a conda environment to set up the necessary dependencies for running the tutorial.
If you haven't downloaded conda yet, you can find the instructions in the [link](https://conda.io/projects/conda/en/stable/user-guide/install/download.html).

```bash
conda create --name tutorial

conda activate tutorial
```

## Downloading reference genome and generating related files

This section provides commands to download a reference genome (GRCh38) and generate related files.
In this tutorial, you will use Bowtie2 as the sequence aligner tool. Therefore, you must install Bowtie2 together with samtools, which is a versatile software package used for manipulating and analyzing SAM/BAM files.

```bash
conda install -c bioconda bowtie2

conda install -c bioconda samtools
```

Next, you will download the reference genome.
Because you will analyze results/HeLa cells that are a type of human cancer cells (derived from cervical cancer cells), GRCh38 genome is chosen as the reference:

```bash
wget ftp://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_human/release_41/GRCh38.p13.genome.fa.gz -O ref_genome/GRCh38.fa.gz && gunzip ref_genome/GRCh38.fa.gz
```

After downloading the genome fasta file, you should generate the index files for bowtie2
which is crucial for efficiently reducing computational time and improving alignment quality.

```bash
bowtie2-build --threads 8 ref_genome/GRCh38.fa ref_genome/Bowtie2/genome_GRCh38
```

You will create another index file via samtools to retrieve sequence information based on genomic coordinates or sequence identifiers.

```bash
samtools faidx ref_genome/GRCh38.fa
```

Next, the index file created by samtools will be converted to a ron file (a different format of the index).
This file will be useful when we simulate our samples with boquila.

```bash
python3 scripts/idx2ron.py -i ref_genome/GRCh38.fa.fai -o ref_genome/GRCh38.ron -l genome_idex2ron.log
```

## Quality control

Here, you'll learn how to perform quality control on the NGS data using FastQC, a tool for assessing the quality of sequencing reads.
A nice [github page](https://hbctraining.github.io/Intro-to-rnaseq-hpc-salmon/lessons/qc_fastqc_assessment.html) for the evaluation of FastQC results.

To run FastQC, you should download the package from bioconda:

```bash
conda install -c bioconda fastqc
```

Then you can create a directory for the output of FastQC with `mkdir qc/` command.
Lastly, you can run the command below to execute the tool for both Damage-seq and XR-seq samples:

```bash
fastqc -t 8 --outdir qc/ samples/hela_ds_cpd.fq 

fastqc -t 8 --outdir qc/ samples/hela_xr_cpd.fq 
```

## Adaptor handling

This section demonstrates how to handle adaptors in the NGS data using Cutadapt, a tool for trimming adaptor sequences and other contaminants.

```bash
conda install -c bioconda cutadapt
```

At this stage, we will perform different tasks for Damage-seq and XR-seq.
In Damage-seq we want to discard all the reads with adaptors
since having the adaptor in Damage-seq reads mean that the read does not contain any damage.
In the case of XR-seq, we will only trim the adaptors from the reads and keep the trimmed ones.

```bash
cutadapt -j 8 -g GACTGGTTCCAATTGAAAGTGCTCTTCCGATCT --discard-trimmed -o results/hela_ds_cpd_cutadapt.fq samples/hela_ds_cpd.fq > hela_ds_cpd_cutadapt.log

cutadapt -j 8 -a TGGAATTCTCGGGTGCCAAGGAACTCCAGTNNNNNNACGATCTCGTATGCCGTCTTCTGCTTG -o results/hela_xr_cpd_cutadapt.fq samples/hela_xr_cpd.fq > hela_xr_cpd_cutadapt.log
```

## Mapping, removing duplicates, quality trimming, and converting to bed

This section covers the steps involved in mapping the preprocessed reads to the reference genome using Bowtie2, converting the mapped reads to BAM format, and extracting BED files.

Initially we will align our reads to the reference genome using the prepared index files.
After that we will convert the output sam files to bam.

```bash
(bowtie2 --threads 8 --seed 1 --reorder -x ref_genome/Bowtie2/genome_GRCh38 -U results/hela_ds_cpd_cutadapt.fq -S results/hela_ds_cpd_cutadapt.sam) > hela_ds_cpd_cutadapt_align.log 2>&1

samtools view -Sbh -o results/hela_ds_cpd_cutadapt.bam results/hela_ds_cpd_cutadapt.sam

(bowtie2 --threads 8 --seed 1 --reorder -x ref_genome/Bowtie2/genome_GRCh38 -U results/hela_xr_cpd_cutadapt.fq -S results/hela_xr_cpd_cutadapt.sam) > hela_xr_cpd_cutadapt_align.log 2>&1

samtools view -Sbh -o results/hela_xr_cpd_cutadapt.bam results/hela_xr_cpd_cutadapt.sam
```

In the next part, we will remove the duplicate reads with picard.
Let's install it.

```bash
conda install -c bioconda picard
```

To run MarkDplicates command of picard (this command will remove the duplicates for us),
you need your files to be ordered by their header.
For that purpose, you should sort the files and then use picard.

```bash
samtools sort -o results/hela_ds_cpd_cutadapt_sorted.bam results/hela_ds_cpd_cutadapt.bam -@ 8 -T results/

samtools sort -o results/hela_xr_cpd_cutadapt_sorted.bam results/hela_xr_cpd_cutadapt.bam -@ 8 -T results/

(picard MarkDuplicates --REMOVE_DUPLICATES true --INPUT results/hela_ds_cpd_cutadapt_sorted.bam --TMP_DIR results/ --OUTPUT results/hela_ds_cpd_cutadapt_sorted_dedup.bam --METRICS_FILE results/hela_ds_cpd_cutadapt_sorted_dedub.metrics.txt) > hela_ds_cpd_picard.log 2>&1

(picard MarkDuplicates --REMOVE_DUPLICATES true --INPUT results/hela_xr_cpd_cutadapt_sorted.bam --TMP_DIR results/ --OUTPUT results/hela_xr_cpd_cutadapt_sorted_dedup.bam --METRICS_FILE results/hela_xr_cpd_cutadapt_sorted_dedub.metrics.txt) > hela_xr_cpd_picard.log 2>&1
```

Lastly, we will remove low quality reads (MAPQ score < 20) via samtools and
use bedtools to convert our bam files into bed format.

```bash
conda install -c bioconda bedtools

samtools index results/hela_ds_cpd_cutadapt_sorted_dedup.bam
samtools view -q 20 -b results/hela_ds_cpd_cutadapt_sorted_dedup.bam |& bedtools bamtobed > results/hela_ds_cpd.bed

samtools index results/hela_xr_cpd_cutadapt_sorted_dedup.bam
samtools view -q 20 -b results/hela_xr_cpd_cutadapt_sorted_dedup.bam |& bedtools bamtobed > results/hela_xr_cpd.bed
```

## Sorting, filtering, calculating length dist., filtering damage-seq samples by motif, producing bigwig files

```bash
```

## Simulating the sample reads

```bash
```

## Plotting length distribution, nucleotide enrichment, and bam correlations

```bash
```

## Running pipeline with snakemake

This section will guide you through running the XR-Seq and Damage-Seq pipeline using Snakemake, a workflow management system. Detailed instructions and code examples can be found in the provided github link: <https://github.com/CompGenomeLab/xr-ds-seq-snakemake>
